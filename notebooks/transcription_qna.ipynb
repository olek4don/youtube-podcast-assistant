{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "\n",
    "client = OpenAI()\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "with open(\"../data/external/test_transcript.json\") as f:\n",
    "    test_transcripts = json.load(f)\n",
    "\n",
    "\n",
    "print(test_transcripts[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def build_prompt(context: str) -> str:\n",
    "    prompt_template = \"\"\"\n",
    "    You're a professional podcast assistant. You will generate QUESTION and ANSWER based on the CONTEXT from text-chunks of the transcript.\n",
    "    Here you will generate a QUESTION for which the CONTEXT is relevant.\n",
    "    The output should be valid JSON, with keys enclosed in double quotes and properly escaped characters.\n",
    "    Respond only with a valid JSON object containing the keys \"question\" and \"answer\".\n",
    "    Do not include any markup formatting or code block syntax.\n",
    "    Avoid to including word \"context\" in the question or answer.\n",
    "    Pattern:\n",
    "    {{\"question\": QUESTION, \"answer\": ANSWER}}\n",
    "    If the text does not contain sufficient information to answer the question, do not make up information and give the answer as \"NA\".\n",
    "    You are only allowed to answer questions related to CONTEXT.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    Remember that the text chunks derive from podcast where podcaster talks with the guest, so if you see diversity of roles in the CONTEXT, try to recognize that.\n",
    "    Focus.\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    prompt = prompt_template.format(context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def rag(context: str):\n",
    "    prompt = build_prompt(context)\n",
    "    answer = llm(prompt)\n",
    "    return json.loads(answer)\n",
    "\n",
    "\n",
    "def add_qa_to_transcripts(transcripts):\n",
    "    \"\"\"Add a \"question\" and \"answer\" prepared by llm to each transcript in the list of transcripts\"\"\"\n",
    "    new_transcripts = []\n",
    "    for transcript in transcripts:\n",
    "        new_qa = rag(transcript[\"text\"])\n",
    "        new_transcript = {**transcript, **new_qa}\n",
    "        new_transcripts.append(new_transcript)\n",
    "    return new_transcripts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "test_transcript = test_transcripts[0][\"text\"]\n",
    "\n",
    "test_rag = rag(test_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "transcripts_with_qa = add_qa_to_transcripts(transcripts)\n",
    "for t in transcripts_with_qa:\n",
    "    print(json.dumps(t, indent=4), end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "with open(\"../data/external/transcript_qna.json\", \"r\") as f:\n",
    "    to_replace = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Function to replace variants of a word\n",
    "def replace_word(text, target_words, replacement_word):\n",
    "    # Use regular expression to replace any variant of the target word\n",
    "    pattern = \"|\".join(re.escape(word) for word in target_words)\n",
    "    return re.sub(\n",
    "        r\"\" + pattern + r\"(?=[\\s]|$)\", replacement_word, text, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "\n",
    "target_words = [\"speaker\", \"the speaker\", \"speaker's\"]\n",
    "\n",
    "# Lists of guests and times\n",
    "guests = [\"Elon Musk\", \"DJ Seo\", \"Matthew McDougall\", \"Bliss Chapman\", \"Noland Arbaugh\"]\n",
    "starts = [\"00:00:00\", \"01:27:34\", \"03:38:39\", \"05:06:01\", \"06:48:53\"]\n",
    "\n",
    "# zip both lists\n",
    "guest_time = [{k: v} for k, v in zip(starts, guests)]\n",
    "print(guest_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "d_guest_time = dict(zip(starts, guests))\n",
    "print(d_guest_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "# # Initialize the current guest to None\n",
    "current_guest = None\n",
    "\n",
    "# Iterate over the transcript_qna\n",
    "for item in to_replace:\n",
    "    # change guest if new guest has appeared in the podcast\n",
    "    for d in guest_time:\n",
    "        for k, v in d.items():\n",
    "            if item[\"start\"] == k:\n",
    "                current_guest = v\n",
    "\n",
    "    # If a guest has appeared, replace variants of the word \"speaker\" with the current guest's name\n",
    "    if current_guest:\n",
    "        item[\"question\"] = replace_word(item[\"question\"], target_words, current_guest)\n",
    "        item[\"answer\"] = replace_word(item[\"answer\"], target_words, current_guest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "def replace_speaker_with_guest(transcript_qna, starts, guests, target_words):\n",
    "    \"\"\"\n",
    "    Replace variants of the word \"speaker\" with the current guest's name in the transcript_qna.\n",
    "\n",
    "    Args:\n",
    "        transcript_qna (list): List of transcript qna items.\n",
    "        starts (list): List of start times for each guest.\n",
    "        guests (list): List of guest names.\n",
    "        target_words (list): List of words to replace (e.g. \"speaker\", \"the speaker\", etc.)\n",
    "\n",
    "    Returns:\n",
    "        list: Modified transcript_qna with replaced speaker names.\n",
    "    \"\"\"\n",
    "    guest_time = dict(zip(starts, guests))\n",
    "    current_guest = None\n",
    "    for item in transcript_qna:\n",
    "        # change guest if new guest has appeared in the podcast\n",
    "        if item[\"start\"] in guest_time:\n",
    "            current_guest = guest_time[item[\"start\"]]\n",
    "        # If a guest has appeared, replace variants of the word \"speaker\" with the current guest's nam\n",
    "        if current_guest:\n",
    "            item[\"question\"] = replace_word(\n",
    "                item[\"question\"], target_words, current_guest\n",
    "            )\n",
    "            item[\"answer\"] = replace_word(item[\"answer\"], target_words, current_guest)\n",
    "\n",
    "    return transcript_qna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "with open(\"../data/external/transcript_qna_parsed.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_json(\"../data/external/transcript_qna_parsed.json\")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "eval_dataset = dataset.to_pandas()\n",
    "eval_dataset.head()\n",
    "# # %%\n",
    "# from pathlib import Path\n",
    "\n",
    "# file_path = \"../data/external/transcript_qna_parsed.json\"\n",
    "# data = json.loads(Path(file_path).read_text())\n",
    "# # %%\n",
    "# from langchain_community.document_loaders import JSONLoader\n",
    "# loader = JSONLoader(\n",
    "#     file_path=\"../data/external/transcript_qna_parsed.json\",\n",
    "#     jq_schema=\".[]\",\n",
    "#     text_content=False,\n",
    "#     json_lines=False,\n",
    "# )\n",
    "\n",
    "# data = loader.load()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
